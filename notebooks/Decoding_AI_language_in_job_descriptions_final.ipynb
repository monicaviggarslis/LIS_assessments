{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iNaPasKkk2n",
        "outputId": "0428188c-1971-4da3-d699-2944a8a88793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIZ7tub0kk2o",
        "outputId": "1211c6ce-35d7-4eb8-e135-386a35054c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded development results: 19 rows\n",
            "\n",
            "Loaded prompt from file\n"
          ]
        }
      ],
      "source": [
        "development_results_path = '../notebooks/my_results_development.csv'\n",
        "prompt_path = '../notebooks/my_best_prompt.txt'\n",
        "\n",
        "# Load development results (for comparison)\n",
        "try:\n",
        "    df_dev = pd.read_csv(development_results_path)\n",
        "    print(f\"Loaded development results: {len(df_dev)} rows\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: Could not find {development_results_path}\")\n",
        "    print(\"You can continue without development data, but you won't be able to compare.\")\n",
        "    df_dev = None\n",
        "\n",
        "# Load your final prompt\n",
        "try:\n",
        "    with open(prompt_path, 'r') as f:\n",
        "        final_prompt = f.read()\n",
        "    print(\"\\nLoaded prompt from file\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: Could not find {prompt_path}\")\n",
        "    print(\"Define your prompt in the cell below.\")\n",
        "    final_prompt = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN2aK8Sxkk2o",
        "outputId": "a693c38a-a2b1-44bb-dcb4-03fa221f990b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final prompt:\n",
            "================================================================================\n",
            "\n",
            "You are a research assistant analysing job descriptions to determine if the language used to describe AI-related responsibilities is vague or concrete.\n",
            "\n",
            "DEFINITION:\n",
            "Answer \"Yes\" (vague AI skill framing) if the job description mentions AI/ML (or related terms) but does NOT specify at least ONE concrete implementation detail such as:\n",
            "- Tasks (build/train/fine-tune/deploy/evaluate/monitor, create prompts/pipelines)\n",
            "- Tools/tech (LLMs, GPT, TensorFlow, PyTorch, scikit-learn, Azure/AWS/GCP, Databricks, vector DB, RAG)\n",
            "- Data/inputs (customer data, documents, logs, images, etc.)\n",
            "- Outputs/deliverables (models, dashboards, copilots, classifiers, forecasts, recommender systems)\n",
            "- Operational details (A/B tests, metrics, drift, MLOps, CI/CD, governance)\n",
            "\n",
            "Answer \"No\" if AI is mentioned AND the posting includes at least ONE clear concrete implementation detail above that is explicitly tied to AI-related work in the role.\n",
            "\n",
            "IMPORTANT RULES:\n",
            "- Consider the entire posting text (including company/mission sections).\n",
            "- If AI is mentioned in the posting, first look for specific tasks, tools, data, outputs, or operational details connected to AI.\n",
            "- If AI is mentioned anywhere in the posting and you do NOT find any specific tasks/tools/data/outputs/operational details tied to AI, answer \"Yes\".\n",
            "- Do NOT treat generic phrases as concrete, such as: \"AI-powered\", \"AI-enabled\", \"leveraging AI\", \"using AI tools\", \"data-driven\", \"intelligent automation\", \"advanced analytics\", \"informed decision-making\", \"innovation\", \"autonomy\", \"computer vision\", \"sensor fusion\" unless the text ALSO specifies named tasks, tools, data, or outputs.\n",
            "- If AI is not mentioned anywhere, answer \"No\".\n",
            "- In borderline or uncertain cases where AI is mentioned but it is unclear whether the description is concrete, answer \"Yes\" (vague AI skill framing).\n",
            "- If AI or related terms are mentioned only in the description of the company, business unit, or its “next‑generation capabilities” (for example, “we harness the power of data and digital to drive capabilities in artificial intelligence, robotics, automation, and analytics”), and there are no AI‑related tasks or tools in the listed responsibilities for this role, answer \"Yes\" (vague AI skill framing).\n",
            "\n",
            "SPECIAL CASE:\n",
            "- If AI or artificial intelligence is mentioned only in the description of the overall organisation or its technology strategy (and not in the specific responsibilities of this role), and there are no concrete AI tasks/tools/data/outputs for the role, answer \"Yes\" (vague AI skill framing).\n",
            "\n",
            "BORDERLINE CASES:\n",
            "- If AI is mentioned only in a generic company/mission statement and not in the role responsibilities, and there are no concrete AI tasks/tools/data/outputs, answer \"Yes\".\n",
            "- If the role describes concrete tasks that clearly depend on an AI or ML system (for example, \"use our ML model output to prioritise leads\") but does not name the model, answer \"No\" because the AI use is operationally specific.\n",
            "- If the posting lists \"AI tools\" or \"AI platforms\" in a skills list but does not describe any specific AI-related tasks, tools, data, or outputs, answer \"Yes\".\n",
            "- If the role sits in a business area that uses AI (e.g. “digital solutions”, “AI, robotics, automation, analytics”) but the responsibilities are standard functional work (such as payroll, HR operations, finance operations) with no explicit AI tasks or tools, answer \"Yes\".\n",
            "\n",
            "FEW-SHOT EXAMPLES:\n",
            "\n",
            "Text: \"Takeda Business Solutions (TBS) … harnesses the power of data and digital to optimize end-to-end processes across Finance, Procurement and HR. TBS is a driver of the latest technology and next generation capabilities in artificial intelligence, robotics, automation, and analytics…\" (This specific Payroll Operations Manager role has no AI-related tasks or tools listed in its responsibilities.)\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"The Mount Sinai Health System … offers comprehensive health care solutions … leveraging innovative approaches such as artificial intelligence and informatics while keeping patients’ medical and emotional needs at the center of all treatment.\" (The specific Medical Assistant role listed in this posting has no AI-related tasks or tools.)\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Drive AI innovation across the organization to enhance decision-making.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Build and deploy machine learning models using Python and TensorFlow to predict customer churn.\"\n",
            "Answer: No\n",
            "\n",
            "Text: \"Leverage AI tools to improve operational efficiency.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Develop LLM-powered document classification pipelines using GPT-4 and a vector database for retrieval-augmented generation.\"\n",
            "Answer: No\n",
            "\n",
            "Text: \"We leverage artificial intelligence and informatics to revolutionize healthcare.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"We leverage artificial intelligence and informatics to transform healthcare delivery.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Our organization uses AI-powered systems to improve operational effectiveness.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"We harness the power of data and digital to optimize end-to-end processes and drive next generation capabilities in artificial intelligence, robotics, automation, and analytics.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"This role uses an AI-based scheduling system developed by a central IT team; no AI development or configuration is required.\"\n",
            "Answer: No\n",
            "\n",
            "TASK:\n",
            "Read the text below and determine if it contains vague AI skill framing.\n",
            "\n",
            "Before answering, check:\n",
            "1) Does the posting mention AI/ML anywhere?\n",
            "2) Does it include a specific task/tool/data/output/operational detail tied to AI?\n",
            "- If (1) yes and (2) no → Yes\n",
            "- If (1) yes and (2) yes → No\n",
            "- If (1) no → No\n",
            "\n",
            "Question: Does this posting contain vague AI skill framing according to the definition above?\n",
            "Respond with ONLY \"Yes\" or \"No\".\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "if final_prompt is None:\n",
        "    final_prompt = \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "print(\"Final prompt:\")\n",
        "print(\"=\"*80)\n",
        "print(final_prompt)\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf_0ngrckk2o",
        "outputId": "6f490655-28af-444a-d537-fb13394c7f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded test data: 38 rows\n",
            "\n",
            "Columns: ['row_id', 'job_id', 'company_name', 'title', 'location', 'sentence_text', 'human_classification', 'full_job_description', 'human_label_yes_no', 'notes']\n",
            "\n",
            "Test set label distribution:\n",
            "human_classification\n",
            "NO     21\n",
            "YES    17\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "test_data_path = '/notebooks/test_set.csv'\n",
        "\n",
        "# Load test data\n",
        "df_test = pd.read_csv(test_data_path)\n",
        "\n",
        "print(f\"Loaded test data: {len(df_test)} rows\")\n",
        "print(f\"\\nColumns: {df_test.columns.tolist()}\")\n",
        "\n",
        "TEXT_COLUMN = 'full_job_description'\n",
        "LABEL_COLUMN = 'human_classification'\n",
        "POSITIVE_LABEL = 'YES'\n",
        "\n",
        "if LABEL_COLUMN in df_test.columns:\n",
        "    print(f\"\\nTest set label distribution:\")\n",
        "    print(df_test[LABEL_COLUMN].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFp3PkhWkk2o"
      },
      "outputs": [],
      "source": [
        "# Helper function for batch classification\n",
        "def classify_batch(texts, prompt, model=\"gpt-4o-mini\", delay=0.5):\n",
        "    \"\"\"\n",
        "    Classify multiple texts using the OpenAI API.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    for text in tqdm(texts, desc=\"Classifying texts\"):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": prompt},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            max_tokens=10\n",
        "        )\n",
        "\n",
        "        prediction = response.choices[0].message.content.strip()\n",
        "        predictions.append(prediction)\n",
        "        time.sleep(delay)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "1b52d1c9f9764e348db3bb133b524cbc",
            "9e94175099034b1fb4cd768768f33bc8",
            "23c0f8f4dd514e299dcf7dd88590a349",
            "b028af5a234b4b139ccaaf00e78b0987",
            "81b933b11ad24db08ee6bfdeb0bc676a",
            "157cbf8f47bc473683f49b25e2abd51d",
            "e9edb2031b914664bbfa71f6f5e51157",
            "4f1ea1b02f6f4dd1946639c4f1e845cb",
            "2f09f699a58e45f3a2f8b619e64c28f7",
            "dbbf7473ea764bdc9354a951c9d2d66f",
            "b8bffa68fb9844608e5f1cc1ce71683c"
          ]
        },
        "id": "pNwjXuXEkk2o",
        "outputId": "29973107-5d8f-414c-eac2-ea205b2c7bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running confirmatory test...\n",
            "\n",
            "This is your final validation. No changes to the prompt after this!\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Classifying texts:   0%|          | 0/38 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b52d1c9f9764e348db3bb133b524cbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set classification complete!\n"
          ]
        }
      ],
      "source": [
        "# Run classification on test set\n",
        "print(\"Running confirmatory test...\\n\")\n",
        "print(\"This is your final validation. No changes to the prompt after this!\\n\")\n",
        "\n",
        "predictions_test = classify_batch(df_test[TEXT_COLUMN].tolist(), final_prompt)\n",
        "\n",
        "# Add predictions to dataframe\n",
        "df_test['prediction'] = predictions_test\n",
        "\n",
        "print(\"\\nTest set classification complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu6B6P-xkk2p"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def calculate_metrics(y_true, y_pred, positive_label=\"Yes\"):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive classification metrics.\n",
        "    \"\"\"\n",
        "    # Convert to binary\n",
        "    y_true_binary = [1 if str(y) == positive_label else 0 for y in y_true]\n",
        "    y_pred_binary = [1 if str(y) == positive_label else 0 for y in y_pred]\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true_binary, y_pred_binary),\n",
        "        'precision': precision_score(y_true_binary, y_pred_binary, zero_division=0),\n",
        "        'recall': recall_score(y_true_binary, y_pred_binary, zero_division=0),\n",
        "        'f1': f1_score(y_true_binary, y_pred_binary, zero_division=0),\n",
        "        'kappa': cohen_kappa_score(y_true_binary, y_pred_binary)\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def print_metrics(metrics, title=\"Classification metrics\"):\n",
        "    \"\"\"Pretty-print metrics\"\"\"\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(title)\n",
        "    print(\"=\"*40)\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric.capitalize():12s}: {value:.3f}\")\n",
        "    print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "GpF4gHSYkk2p",
        "outputId": "84eb97e5-143b-4e6a-b2f1-a22a5923fe4a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAJPCAYAAADi9tloAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATrVJREFUeJzt3Xd4VNX6//3PpIdUCAkQCBAIhBaDglioOQRywENT5AuihKYgItKL/pBOwEZTqkrxwEFQREAsoFQpStOD9N5FaYFgQkj28wcn8zAkYAZmyJD9fnHty8zaa9a+J4C5udfaa1sMwzAEAACAfM8trwMAAADA/UHiBwAAYBIkfgAAACZB4gcAAGASJH4AAAAmQeIHAABgEiR+AAAAJkHiBwAAYBIkfgAAACZB4gfggfD222+rTJkycnd3V9WqVR0+fvv27VW6dGmHj/ugmzVrliwWi44cOZLXoQBwABI/IAcWiyVXx+rVq+/5WlevXtXQoUMdMpa9du3apaFDh7r8D/XvvvtO/fv3V82aNTVz5kyNHj06r0N6IE2ePFmzZs3K6zAA5CELz+oFsvv3v/9t83rOnDlasWKFPvnkE5v2Bg0aqEiRIvd0rT///FOhoaEaMmSIhg4dek9j2euzzz7Ts88+q1WrVqlevXr39dr2GDhwoN5++2399ddf8vLycso10tPTlZmZKW9vb6eM7wqqVKmiwoUL2/WPjIyMDKWnp8vb21sWi8V5wQG4LzzyOgDAFT3//PM2rzdt2qQVK1Zka8f9cfbsWfn6+jot6ZMkT09Pp439IEpJSZGfn5/c3d3l7u6e1+EAcBCmeoG7lJmZqfHjx6ty5cry8fFRkSJF1KVLF124cMGm35YtW5SQkKDChQvL19dXkZGR6tixoyTpyJEjCg0NlSQNGzbMOoV8p8pfenq6hg0bpnLlysnHx0chISGqVauWVqxYYdNvz549atmypQoVKiQfHx9Vr15dS5YssZ6fNWuWnn32WUlSXFxcrqev9+zZo1atWik0NFS+vr6Kjo7WG2+8YdNn+/btatSokQIDA+Xv76/69etr06ZNNn2y1o79+OOP6t27t0JDQ+Xn56cWLVrojz/+sPazWCyaOXOmUlJSrDHOmjVLR44csX59q1u/h5cvX1bPnj1VunRpeXt7KywsTA0aNNC2bdusfXJa45eSkqI+ffooIiJC3t7eio6O1jvvvKNbJ0osFou6d++uxYsXq0qVKvL29lblypX1zTff3PF7KUmrV6+WxWLRggULNGzYMBUvXlwBAQFq2bKlLl26pLS0NPXs2VNhYWHy9/dXhw4dlJaWZjPGzJkz9Y9//ENhYWHy9vZWpUqVNGXKFJs+pUuX1m+//aY1a9ZYv49ZVd6s34s1a9aoW7duCgsLU4kSJWzOZS0H+OGHH+Tm5qY333zTZvx58+bJYrFkuy4A10LFD7hLXbp00axZs9ShQwf16NFDhw8f1vvvv6/t27frxx9/lKenp86ePauGDRsqNDRUAwcOVHBwsI4cOaJFixZJkkJDQzVlyhS9/PLLatGihZ5++mlJ0kMPPXTb6w4dOlRJSUnq3LmzatSooeTkZG3ZskXbtm1TgwYNJEm//fabatasqeLFi2vgwIHy8/PTggUL1Lx5c33++edq0aKF6tSpox49emjixIl6/fXXVbFiRUmy/jcnv/76q2rXri1PT0+99NJLKl26tA4ePKilS5dq1KhR1mvXrl1bgYGB6t+/vzw9PTVt2jTVq1dPa9as0WOPPWYz5quvvqqCBQtqyJAhOnLkiMaPH6/u3bvr008/lSR98sknmj59un766Sd9+OGHkqQnn3zSrt+rrl276rPPPlP37t1VqVIlnTt3TuvXr9fu3bv1yCOP5PgewzDUtGlTrVq1Sp06dVLVqlX17bffql+/fjp58qTGjRtn03/9+vVatGiRunXrpoCAAE2cOFHPPPOMjh07ppCQkL+NMSkpSb6+vho4cKAOHDigSZMmydPTU25ubrpw4YKGDh2qTZs2adasWYqMjLRJvKZMmaLKlSuradOm8vDw0NKlS9WtWzdlZmbqlVdekSSNHz9er776qvz9/a2J+q3LFLp166bQ0FC9+eabSklJyTHOf/zjH+rWrZuSkpLUvHlzPfLIIzp9+rReffVVxcfHq2vXrn/7WQHkIQPA33rllVeMm/+6rFu3zpBkzJ0716bfN998Y9P+xRdfGJKMn3/++bZj//HHH4YkY8iQIbmKJTY21njqqafu2Kd+/fpGTEyMkZqaam3LzMw0nnzySaNcuXLWtoULFxqSjFWrVuXq2nXq1DECAgKMo0eP2rRnZmZav27evLnh5eVlHDx40Np26tQpIyAgwKhTp461bebMmYYkIz4+3ub9vXr1Mtzd3Y2LFy9a2xITEw0/Pz+bax4+fNiQZMycOTNbnLd+P4OCgoxXXnnljp8tMTHRKFWqlPX14sWLDUnGyJEjbfq1bNnSsFgsxoEDB2yu5+XlZdP2yy+/GJKMSZMm3fG6q1atMiQZVapUMa5du2Ztb9OmjWGxWIxGjRrZ9H/iiSds4jQMw7h69Wq2cRMSEowyZcrYtFWuXNmoW7dutr5Zvxe1atUyrl+/nuO5w4cPW9tSUlKMqKgoo3LlykZqaqrx1FNPGYGBgdn+XABwPUz1Andh4cKFCgoKUoMGDfTnn39aj2rVqsnf31+rVq2SJAUHB0uSli1bpvT0dIdcOzg4WL/99pv279+f4/nz58/rhx9+UKtWrXT58mVrbOfOnVNCQoL279+vkydP2n3dP/74Q2vXrlXHjh1VsmRJm3NZi/4zMjL03XffqXnz5ipTpoz1fLFixfTcc89p/fr1Sk5OtnnvSy+9ZHPTQO3atZWRkaGjR4/aHePtBAcHa/PmzTp16lSu37N8+XK5u7urR48eNu19+vSRYRj6+uuvbdrj4+NVtmxZ6+uHHnpIgYGBOnToUK6u165dO5t1ho899pgMw7AuC7i5/fjx47p+/bq1zdfX1/r1pUuX9Oeff6pu3bo6dOiQLl26lKvrS9KLL76Yq/V8BQoU0KxZs7R7927VqVNHX331lcaNG5ftzwUA10PiB9yF/fv369KlSwoLC1NoaKjNceXKFZ09e1aSVLduXT3zzDMaNmyYChcurGbNmmnmzJnZ1mjZY/jw4bp48aLKly+vmJgY9evXT7/++qv1/IEDB2QYhgYPHpwttiFDhkiSNT57ZCUwVapUuW2fP/74Q1evXlV0dHS2cxUrVlRmZqaOHz9u035rslCwYEFJyrZW8l689dZb2rlzpyIiIlSjRg0NHTr0bxOyo0ePKjw8XAEBATbtWVPhtyamOSU9BQsWzPXnuPX9QUFBkqSIiIhs7ZmZmTYJ3Y8//qj4+Hj5+fkpODhYoaGhev311yXJrsQvMjIy131r1qypl19+WT/99JMSEhKyJagAXBNr/IC7kJmZqbCwMM2dOzfH81k3bFgsFn322WfatGmTli5dqm+//VYdO3bUu+++q02bNsnf39/ua9epU0cHDx7Ul19+qe+++04ffvihxo0bp6lTp6pz587KzMyUJPXt21cJCQk5jhEVFWX3dZ3ldhUm4292mrrd1iIZGRnZ2lq1aqXatWvriy++0Hfffae3335bY8eO1aJFi9SoUSP7g87B3X6Ov3v/34178OBB1a9fXxUqVNB7772niIgIeXl5afny5Ro3bpz1z0Nu3Fw5/DtpaWnWG4EOHjyoq1evqkCBArl+P4C8QeIH3IWyZctq5cqVqlmzZq5+WD7++ON6/PHHNWrUKM2bN09t27bV/Pnz1blz57vaG61QoULq0KGDOnTooCtXrqhOnToaOnSoOnfubJ1i9fT0VHx8/B3HsefaWePu3Lnztn1CQ0NVoEAB7d27N9u5PXv2yM3NLVsF625lVQYvXrxo0367KeJixYqpW7du6tatm86ePatHHnlEo0aNum3iV6pUKa1cuVKXL1+2qfrt2bPHet4VLF26VGlpaVqyZIlN1TBrucHNHLkP35AhQ7R792698847GjBggAYOHKiJEyc6bHwAzsFUL3AXWrVqpYyMDI0YMSLbuevXr1uTkQsXLmSr+GQ9bixrujerSnJrAnM7586ds3nt7++vqKgo63hhYWGqV6+epk2bptOnT2d7/81bpfj5+eX62qGhoapTp44+/vhjHTt2zOZc1md0d3dXw4YN9eWXX9o8DeT333/XvHnzVKtWLQUGBubqc/6dwMBAFS5cWGvXrrVpnzx5ss3rjIyMbNOdYWFhCg8Pv+OUe+PGjZWRkaH333/fpn3cuHGyWCwOqxTeq6yK4M1/zi5duqSZM2dm6+vn55frP2d3snnzZr3zzjvq2bOn+vTpo379+un999/XmjVr7nlsAM5FxQ+4C3Xr1lWXLl2UlJSkHTt2qGHDhvL09NT+/fu1cOFCTZgwQS1bttTs2bM1efJktWjRQmXLltXly5c1Y8YMBQYGqnHjxpJuTK9VqlRJn376qcqXL69ChQqpSpUqt11LV6lSJdWrV0/VqlVToUKFtGXLFutWJVk++OAD1apVSzExMXrxxRdVpkwZ/f7779q4caNOnDihX375RdKNJNTd3V1jx47VpUuX5O3tbd0PLicTJ05UrVq19Mgjj+ill15SZGSkjhw5oq+++ko7duyQJI0cOVIrVqxQrVq11K1bN3l4eGjatGlKS0vTW2+95cDfBalz584aM2aMOnfurOrVq2vt2rXat2+fTZ/Lly+rRIkSatmypWJjY+Xv76+VK1fq559/1rvvvnvbsZs0aaK4uDi98cYbOnLkiGJjY/Xdd9/pyy+/VM+ePW1u5MhLDRs2lJeXl5o0aaIuXbroypUrmjFjhsLCwrIl/tWqVdOUKVM0cuRIRUVFKSwsTP/4xz/sul5qaqoSExNVrlw56xY+w4YN09KlS9WhQwf997//tf6DAoALyrP7iYEHyK3buWSZPn26Ua1aNcPX19cICAgwYmJijP79+xunTp0yDMMwtm3bZrRp08YoWbKk4e3tbYSFhRn/+te/jC1bttiMs2HDBqNatWqGl5fX327tMnLkSKNGjRpGcHCw4evra1SoUMEYNWqUzVYghmEYBw8eNNq1a2cULVrU8PT0NIoXL27861//Mj777DObfjNmzDDKlCljuLu752prl507dxotWrQwgoODDR8fHyM6OtoYPHiwTZ9t27YZCQkJhr+/v1GgQAEjLi7O2LBhg02frG1Cbt3qJmt7k5vjyGk7F8O4sY1Jp06djKCgICMgIMBo1aqVcfbsWZvvYVpamtGvXz8jNjbWCAgIMPz8/IzY2Fhj8uTJNmPdup2LYRjG5cuXjV69ehnh4eGGp6enUa5cOePtt9+22X7GMG5s55LTdjGlSpUyEhMTc/o2Zvu8CxcuzNX3Z8iQIYYk448//rC2LVmyxHjooYcMHx8fo3Tp0sbYsWONjz/+ONs2LGfOnDGeeuopIyAgwJBk3drldte6+VzWOFnb7WzevNmm35YtWwwPDw/j5ZdfvuPnBZC3eFYvAACASbDGDwAAwCRI/AAAAEyCxA8AAMAkSPwAAABMgsQPAADAJEy/j19mZqZOnTqlgIAAh+5qDwAAbjAMQ5cvX1Z4eLjc3Fyn5pSamqpr1645bXwvLy/5+Pg4bfy7YfrE79SpUw57hBQAALi948ePq0SJEnkdhqQbSZ9vQIh0/arTrlG0aFEdPnzYpZI/0yd+Wc/g9KqUKIu7Vx5HAyA3ls5+I69DAGCHlCuX1aJOjM1zr/PatWvXpOtX5V0pUXLGz/+Mazqza7auXbtG4udKsqZ3Le5eJH7AA8LP3zHP+wVwf7nkkioPH6f8/DcsrjOlfTPXjAoAAAAOZ/qKHwAAMDGLJGdUIl2wuClR8QMAADANKn4AAMC8LG43DmeM64JcMyoAAAA4HBU/AABgXhaLk9b4ueYiPyp+AAAAJkHFDwAAmBdr/AAAAJAfUfEDAADmZbI1fiR+AADAxJw01euik6quGRUAAAAcjoofAAAwL5NN9VLxAwAAMAkqfgAAwLzYzgUAAAD5ERU/AABgXqzxAwAAQH5ExQ8AAJgXa/wAAACQH1HxAwAA5sUaPwAAAORHVPwAAIB5mWyNH4kfAAAwL4vFSYkfU70AAADIQ1T8AACAeblZbhzOGNcFUfEDAAAwCSp+AADAvEx2c4drRgUAAACHo+IHAADMiw2cAQAAkB9R8QMAAObFGj8AAADkRyR+AADAvLLW+DnjsMPatWvVpEkThYeHy2KxaPHixbft27VrV1ksFo0fP97uj0viBwAAkMdSUlIUGxurDz744I79vvjiC23atEnh4eF3dR3W+AEAAPNykTV+jRo1UqNGje7Y5+TJk3r11Vf17bff6qmnnrqrsEj8AACAeTl5O5fk5GSbZm9vb3l7e9s9XGZmpl544QX169dPlStXvuuwmOoFAABwkoiICAUFBVmPpKSkuxpn7Nix8vDwUI8ePe4pHip+AADAvJw81Xv8+HEFBgZam++m2rd161ZNmDBB27Ztk+Ueq5NU/AAAAJwkMDDQ5ribxG/dunU6e/asSpYsKQ8PD3l4eOjo0aPq06ePSpcubddYVPwAAIB5PQCPbHvhhRcUHx9v05aQkKAXXnhBHTp0sGssEj8AAIA8duXKFR04cMD6+vDhw9qxY4cKFSqkkiVLKiQkxKa/p6enihYtqujoaLuuQ+IHAABMzElr/OxcTbdlyxbFxcVZX/fu3VuSlJiYqFmzZjksKhI/AACAPFavXj0ZhpHr/keOHLmr65D4AQAA83oA1vg5Enf1AgAAmAQVPwAAYF4Wi5P28aPiBwAAgDxExQ8AAJiXk5/c4WpI/AAAgHlxcwcAAADyIyp+AADAvEw21euaUQEAAMDhqPgBAADzYo0fAAAA8iMqfgAAwLxY4wcAAID8iIofAAAwL9b4AQAAID+i4gcAAEzLYrHIYqKKH4kfAAAwLbMlfkz1AgAAmAQVPwAAYF6W/x3OGNcFUfEDAAAwCSp+AADAtFjjBwAAgHyJih8AADAtKn4AAADIl6j4AQAA06LiBwAAgHyJih8AADAtKn4AAADIl6j4AQAA8zLZkztI/AAAgGkx1QsAAIB8iYofAAAwLYtFTqr4OX5IR6DiBwAAYBJU/AAAgGlZ5KQ1fi5a8qPiBwAAYBJU/AAAgGlxVy8AAADyJSp+AADAvEy2gTMVPwAAAJOg4gcAAMzLSWv8DNb4AQAAIC9R8QMAAKblrLt6nbM34L0j8QMAAKZltsSPqV4AAACToOIHAADMi+1cAAAAkB9R8QMAAKbFGj8AAADkS1T8AACAaVHxAwAAQL5ExQ8AAJgWFT8AAADkS1T8AACAaVHxAwAAQL5ExQ8AAJiXyZ7cQeIHAABMi6leAAAA5EtU/AAAgGlR8QMAAEC+RMUPAACYFhU/AAAA5EtU/AAAgHmZbDsXKn4AAAAmQcUPAACYFmv8AAAAkC9R8QMAAKZFxQ8AAAD5EhU/PNCefLisXn0hXrEVSqpYaJDa9p2u5Wt+tZ7/YMjzeu5fj9u8Z+XGXXq2x+T7HSqA2/jjfLJm/Ptb/bRjv9LS0lW8aCH16/a0ossWz+vQYAIWOani56K39bpcxa99+/ayWCwaM2aMTfvixYttfmMyMjI0btw4xcTEyMfHRwULFlSjRo30448/3u+QkYcK+Hpr576T6vfWp7fts3LDb4r+5yDr0fmNmfcxQgB3cvnKX3pt8Ax5eLhrzOvt9PG4HurarpEC/HzzOjSYRNZUrzMOe6xdu1ZNmjRReHi4LBaLFi9ebD2Xnp6uAQMGKCYmRn5+fgoPD1e7du106tQpuz+vyyV+kuTj46OxY8fqwoULOZ43DEOtW7fW8OHD9dprr2n37t1avXq1IiIiVK9ePZtvFvK3lRt2adTUZfpq9a+37ZN27brOnrtsPS5d/us+RgjgTuZ/uU6hIUHq3+1pVYgqoWJhBVU9NkrhRQvldWjAfZWSkqLY2Fh98MEH2c5dvXpV27Zt0+DBg7Vt2zYtWrRIe/fuVdOmTe2+jktO9cbHx+vAgQNKSkrSW2+9le38ggUL9Nlnn2nJkiVq0qSJtX369Ok6d+6cOnfurAYNGsjPz+9+hg0XVataOe37NkkXL1/Vup/3aeTUZbpwKSWvwwIgacOWPXo0NkrD3puvX3cdUeFCAWra8DE9FV89r0ODWbjIBs6NGjVSo0aNcjwXFBSkFStW2LS9//77qlGjho4dO6aSJUvm+jouWfFzd3fX6NGjNWnSJJ04cSLb+Xnz5ql8+fI2SV+WPn366Ny5c9m+QVnS0tKUnJxscyD/+n7Dbr089BM17zZJQyd9qScfidLCCS/Lzc01114AZnP67AUtWfGzihcN0Zg32qlJwxp6f+ZX+nb19rwODXCIW3OOtLQ0h4x76dIlWSwWBQcH2/U+l0z8JKlFixaqWrWqhgwZku3cvn37VLFixRzfl9W+b9++HM8nJSUpKCjIekRERDguaLicRSu26uu1/9Wug6e0fM2vat17qqpVLq1a1crldWgAJBmZhspFFlPn5xqoXGS4/hX/qJ6qX11LV/yc16HBJJy9xi8iIsIm70hKSrrnmFNTUzVgwAC1adNGgYGBdr3XZRM/SRo7dqxmz56t3bt3ZztnGMZdjTlo0CBdunTJehw/fvxew8QD5OjJc/rzwmWVKRGa16EAkFSooL9KlQizaStZIlRn/7yYNwEBDnb8+HGbvGPQoEH3NF56erpatWolwzA0ZcoUu9/vkmv8stSpU0cJCQkaNGiQ2rdvb20vX758jsmgJGt7+fLlczzv7e0tb29vh8eKB0N4WLAKBfnp93NM8QOuoEp0SR0/9adN24lTf6pIaHDeBATTcfYGzoGBgXZX5W4nK+k7evSofvjhh7sa16UrfpI0ZswYLV26VBs3brS2tW7dWvv379fSpUuz9X/33XcVEhKiBg0a3M8wkUf8fL1UpXxxVSl/Y7+vUuEhqlK+uEoUKSg/Xy8N79Fc1auUVkSxQqrzaHnNfeclHTr+p77fmPM/HADcX8889aR27z+uuYvW6OSZc/p+/S/66vstapbwWF6HBriUrKRv//79WrlypUJCQu5qHJeu+ElSTEyM2rZtq4kTJ1rbWrdurYULFyoxMVFvv/226tevr+TkZH3wwQdasmSJFi5cyB29JlG1Yiktm/aa9fXo3s9IkuYt26Q+Yz5Vpajiav3UYwoK8NWZPy7ph817NHrqMl1Lv55XIQO4SYWoEhrW9zl9NO87ffL5ahULC1a3xMaKrx2b16HBJCyWG4czxrXHlStXdODAAevrw4cPa8eOHSpUqJCKFSumli1batu2bVq2bJkyMjJ05swZSVKhQoXk5eWV+7iMu10s5yTt27fXxYsXbfbiO3LkiKKjo3Xt2jXr2r7r169r/PjxmjVrlvbv3y8fHx898cQTGjx4sGrWrJnr6yUnJysoKEjeMS/K4p77bxyAvPP9ghF5HQIAO6RcSVbDR0rr0qVLDpv2vFdZP/8ju38mN+8CDh8/M+2qDr/fMtefefXq1YqLi8vWnpiYqKFDhyoyMjLH961atUr16tXLdVwuV/GbNWtWtrbSpUtnu/3Zw8NDffv2Vd++fe9TZAAAIL+5UfFzxho/+/rXq1fvjjeuOqpO53KJHwAAwH3jpKleF31Ur+vf3AEAAADHoOIHAABMy9nbubgaKn4AAAAmQcUPAACYlqts53K/UPEDAAAwCSp+AADAtNzcLHJzc3x5znDCmI5AxQ8AAMAkqPgBAADTYo0fAAAA8iUqfgAAwLTYxw8AAAD5EhU/AABgWmZb40fiBwAATIupXgAAAORLVPwAAIBpUfEDAABAvkTFDwAAmJbZbu6g4gcAAGASVPwAAIBpWeSkNX5yzZIfFT8AAACToOIHAABMizV+AAAAyJeo+AEAANNiHz8AAADkS1T8AACAaZltjR+JHwAAMC2megEAAJAvUfEDAACmZbapXip+AAAAJkHFDwAAmBZr/AAAAJAvUfEDAADm5aQ1fnLNgh8VPwAAALOg4gcAAEyLNX4AAADIl6j4AQAA02IfPwAAAORLVPwAAIBpmW2NH4kfAAAwLaZ6AQAAkC9R8QMAAKZltqleKn4AAAAmQcUPAACYFhU/AAAA5EtU/AAAgGlxVy8AAADyJSp+AADAtFjjBwAAgHyJih8AADAt1vgBAAAgX6LiBwAATMtsa/xI/AAAgGlZ5KSpXscP6RBM9QIAAJgEFT8AAGBabhaL3JxQ8nPGmI5AxQ8AAMAkqPgBAADTYjsXAAAA5EtU/AAAgGmZbTsXKn4AAAAmQcUPAACYlpvlxuGMcV0RFT8AAACToOIHAADMy+Kk9XguWvEj8QMAAKbFdi4AAADIl6j4AQAA07L875czxnVFVPwAAABMgoofAAAwLbZzAQAAwH21du1aNWnSROHh4bJYLFq8eLHNecMw9Oabb6pYsWLy9fVVfHy89u/fb/d1SPwAAIBpZT2yzRmHPVJSUhQbG6sPPvggx/NvvfWWJk6cqKlTp2rz5s3y8/NTQkKCUlNT7boOU70AAAB5rFGjRmrUqFGO5wzD0Pjx4/X//t//U7NmzSRJc+bMUZEiRbR48WK1bt0619eh4gcAAEwrax8/ZxySlJycbHOkpaXZHePhw4d15swZxcfHW9uCgoL02GOPaePGjXaNReIHAADgJBEREQoKCrIeSUlJdo9x5swZSVKRIkVs2osUKWI9l1tM9QIAANNys1jk5oTHbGSNefz4cQUGBlrbvb29HX4te1DxAwAAcJLAwECb424Sv6JFi0qSfv/9d5v233//3Xout0j8AACAaTl7jZ8jREZGqmjRovr++++tbcnJydq8ebOeeOIJu8ZiqhcAAJjW3Wy9kttx7XHlyhUdOHDA+vrw4cPasWOHChUqpJIlS6pnz54aOXKkypUrp8jISA0ePFjh4eFq3ry5Xdch8QMAAMhjW7ZsUVxcnPV17969JUmJiYmaNWuW+vfvr5SUFL300ku6ePGiatWqpW+++UY+Pj52XYfEDwAAmJajp2VvHtce9erVk2EYdxjPouHDh2v48OH3FBdr/AAAAEwiVxW/JUuW5HrApk2b3nUwAAAA95Ozt3NxNblK/HK7cNBisSgjI+Ne4gEAAICT5Crxy8zMdHYcAAAA953lf4czxnVF97TGLzU11VFxAAAAwMnsTvwyMjI0YsQIFS9eXP7+/jp06JAkafDgwfroo48cHiAAAICzZO3j54zDFdmd+I0aNUqzZs3SW2+9JS8vL2t7lSpV9OGHHzo0OAAAADiO3YnfnDlzNH36dLVt21bu7u7W9tjYWO3Zs8ehwQEAADiTm8V5hyuyO/E7efKkoqKisrVnZmYqPT3dIUEBAADA8exO/CpVqqR169Zla//ss8/08MMPOyQoAACA+8Fsa/zsfmTbm2++qcTERJ08eVKZmZlatGiR9u7dqzlz5mjZsmXOiBEAAMBpXDRHcwq7K37NmjXT0qVLtXLlSvn5+enNN9/U7t27tXTpUjVo0MAZMQIAAMAB7K74SVLt2rW1YsUKR8cCAABwXzlrWjbfTPVm2bJli3bv3i3pxrq/atWqOSwoAAAAOJ7did+JEyfUpk0b/fjjjwoODpYkXbx4UU8++aTmz5+vEiVKODpGAAAAp3DW1iv5ZjuXzp07Kz09Xbt379b58+d1/vx57d69W5mZmercubMzYgQAAIAD2F3xW7NmjTZs2KDo6GhrW3R0tCZNmqTatWs7NDgAAABnMtsaP7srfhERETlu1JyRkaHw8HCHBAUAAADHszvxe/vtt/Xqq69qy5Yt1rYtW7botdde0zvvvOPQ4AAAAJzJ4sTDFeVqqrdgwYI2JcuUlBQ99thj8vC48fbr16/Lw8NDHTt2VPPmzZ0SKAAAAO5NrhK/8ePHOzkMAACA+8/NYpGbE9bjOWNMR8hV4peYmOjsOAAAAOBkd72BsySlpqbq2rVrNm2BgYH3FBAAAMD9YrE451m9Llrwsz/xS0lJ0YABA7RgwQKdO3cu2/mMjAyHBAYAAOBsbOfyN/r3768ffvhBU6ZMkbe3tz788EMNGzZM4eHhmjNnjjNiBAAAgAPYXfFbunSp5syZo3r16qlDhw6qXbu2oqKiVKpUKc2dO1dt27Z1RpwAAAAOZ7apXrsrfufPn1eZMmUk3VjPd/78eUlSrVq1tHbtWsdGBwAAAIexO/ErU6aMDh8+LEmqUKGCFixYIOlGJTA4ONihwQEAADhT1nYuzjhckd2JX4cOHfTLL79IkgYOHKgPPvhAPj4+6tWrl/r16+fwAAEAAOAYdq/x69Wrl/Xr+Ph47dmzR1u3blVUVJQeeughhwYHAADgTGZb43dP+/hJUqlSpVSqVClHxAIAAAAnylXiN3HixFwP2KNHj7sOBgAA4H4y2z5+uUr8xo0bl6vBLBbLA5v4HVv9Dk8dAR4QBRu/k9chALCDcT01r0PA/+Qq8cu6ixcAACA/cdNd3Omay3FdkavGBQAAAAe755s7AAAAHlSs8QMAADAJi0VyM9F2Lkz1AgAAmAQVPwAAYFpuTqr4OWNMR7irit+6dev0/PPP64knntDJkyclSZ988onWr1/v0OAAAADgOHYnfp9//rkSEhLk6+ur7du3Ky0tTZJ06dIljR492uEBAgAAOEvWzR3OOFyR3YnfyJEjNXXqVM2YMUOenp7W9po1a2rbtm0ODQ4AAACOY/cav71796pOnTrZ2oOCgnTx4kVHxAQAAHBfsMbvbxQtWlQHDhzI1r5+/XqVKVPGIUEBAADA8exO/F588UW99tpr2rx5sywWi06dOqW5c+eqb9++evnll50RIwAAgFNYLM47XJHdU70DBw5UZmam6tevr6tXr6pOnTry9vZW37599eqrrzojRgAAADiA3YmfxWLRG2+8oX79+unAgQO6cuWKKlWqJH9/f2fEBwAA4DRuFovcnFCec8aYjnDXGzh7eXmpUqVKjowFAADgvnKTcx5j5qqPRrM78YuLi7vj3jQ//PDDPQUEAAAA57A78atatarN6/T0dO3YsUM7d+5UYmKio+ICAABwOmfdiOGiM732J37jxo3LsX3o0KG6cuXKPQcEAAAA53DYFPTzzz+vjz/+2FHDAQAAOJ2bLNYbPBx6yDVLfg5L/DZu3CgfHx9HDQcAAAAHs3uq9+mnn7Z5bRiGTp8+rS1btmjw4MEOCwwAAMDZWOP3N4KCgmxeu7m5KTo6WsOHD1fDhg0dFhgAAAAcy67ELyMjQx06dFBMTIwKFizorJgAAADuCzfLjcMZ47oiu9b4ubu7q2HDhrp48aKTwgEAAICz2H1zR5UqVXTo0CFnxAIAAHBfWSxyyl29rrrGz+7Eb+TIkerbt6+WLVum06dPKzk52eYAAACAa8r1Gr/hw4erT58+aty4sSSpadOmNo9uMwxDFotFGRkZjo8SAADACbir9zaGDRumrl27atWqVc6MBwAA4L4x280duU78DMOQJNWtW9dpwQAAAMB57NrOxeKqdUsAAIC7YPnfL2eM64rsSvzKly//t8nf+fPn7ykgAAAAOIddid+wYcOyPbkDAADgQcUavzto3bq1wsLCnBULAAAAnCjXiR/r+wAAQH5jtopfrjdwzrqrFwAAAA+mXFf8MjMznRkHAADAfWexWJwyq+mqM6V2P7INAAAAjpORkaHBgwcrMjJSvr6+Klu2rEaMGOGU2Va7bu4AAADIT1xhjd/YsWM1ZcoUzZ49W5UrV9aWLVvUoUMHBQUFqUePHg6Ni8QPAADASZKTk21ee3t7y9vb26Ztw4YNatasmZ566ilJUunSpfWf//xHP/30k8PjYaoXAACYlsXivEOSIiIiFBQUZD2SkpKyxfDkk0/q+++/1759+yRJv/zyi9avX69GjRo5/PNS8QMAAKblZrHIzQk3YmSNefz4cQUGBlrbb632SdLAgQOVnJysChUqyN3dXRkZGRo1apTatm3r8LhI/AAAAJwkMDDQJvHLyYIFCzR37lzNmzdPlStX1o4dO9SzZ0+Fh4crMTHRofGQ+AEAANNyhZs7+vXrp4EDB6p169aSpJiYGB09elRJSUkOT/xY4wcAAJCHrl69Kjc325TM3d3dKXsoU/EDAADmddONGI4eN7eaNGmiUaNGqWTJkqpcubK2b9+u9957Tx07dnR4WCR+AAAAeWjSpEkaPHiwunXrprNnzyo8PFxdunTRm2++6fBrkfgBAADTcpNFbvaU5+wYN7cCAgI0fvx4jR8/3uFx3Io1fgAAACZBxQ8AAJiWxUlr/JyybtABqPgBAACYBBU/AABgWq6wj9/9RMUPAADAJKj4AQAA03L2s3pdDYkfAAAwLW7uAAAAQL5ExQ8AAJiWm5w01euETaEdgYofAACASVDxAwAApsUaPwAAAORLVPwAAIBpuck5VTBXray5alwAAABwMCp+AADAtCwWiyxOWJDnjDEdgYofAACASVDxAwAApmX53+GMcV0RFT8AAACToOIHAABMy83ipCd3uOgaPxI/AABgaq6ZojkHU70AAAAmQcUPAACYFo9sAwAAQL5ExQ8AAJgWGzgDAAAgX6LiBwAATMtNzqmCuWplzVXjAgAAgINR8QMAAKbFGj8AAADkS1T8AACAaVnknCd3uGa9j8QPAACYGFO9AAAAyJeo+AEAANNiOxcAAADkS1T8AACAabHGDwAAAPkSFT8AAGBaZtvOhYofAACASVDxAwAApmWx3DicMa4rouIHAABgElT8AACAabnJIjcnrMhzxpiOQMUPAADAJKj4AQAA0zLbGj8SPwAAYFqW//1yxriuiKleAAAAk6DiBwAATMtsU71U/AAAAEyCih8AADAti5O2c2GNHwAAAPIUFT8AAGBarPEDAABAvkTFDwAAmBYVPwAAAORLVPwAAIBp8eQOAAAA5EtU/AAAgGm5WW4czhjXFZH4AQAA02KqFwAAAPkSFT8AAGBabOcCAACAfImKHwAAMC2LnLMez0ULflT8AAAAzIKKHwAAMC2zbedCxQ8AAMAkqPgBAADTYh8/AAAA5EtU/JCvfPTZOn38+TodP31eklShTFH169RIDWpWzuPIAGR5skoJvfrMo4qNKqJiIf5qO2Kxlm88kGPf97rHq0Pjqho07QdN/XLbfY4UZsA+fsADLDwsWEO6N9OqOf31w+x+ql29vNr2na7dB0/ndWgA/qeAj6d2Hj6rfpNX3rHfU09EqXp0uE79efk+RQbkf3mS+BmGofj4eCUkJGQ7N3nyZAUHB+vf//63LBZLjseZM2ckSVevXtWgQYNUtmxZ+fj4KDQ0VHXr1tWXX355vz8SXESjOjFqWLOyypYMU1SpIhrcran8Cnhry87DeR0agP9ZueWwRs35UV/dpsonScVC/DX25fp66e2vdD0j8z5GB7OxOPGwx8mTJ/X8888rJCREvr6+iomJ0ZYtW+7x02WXJ1O9FotFM2fOVExMjKZNm6YuXbpIkg4fPqz+/ftrypQpKlGihCRp7969CgwMtHl/WFiYJKlr167avHmzJk2apEqVKuncuXPasGGDzp07d38/EFxSRkamFn+/TVf/uqZHYyLzOhwAuWSxSFP7Ntakz3/WnmP8/xzO5SaL3JwwL+tmR+p34cIF1axZU3Fxcfr6668VGhqq/fv3q2DBgg6PK8/W+EVERGjChAnq3r27GjZsqNKlS6tTp05q2LChXnjhBa1evVrSjSQvODg4xzGWLFmiCRMmqHHjxpKk0qVLq1q1ane8blpamtLS0qyvk5OTHfJ54Dp+O3BSCR3fVeq16/Lz9dYnb7+oCmWK5XVYAHKp57M1dD0jU9NY04d84NY8w9vbW97e3jZtY8eOVUREhGbOnGlti4x0TsEiT9f4JSYmqn79+urYsaPef/997dy5U9OmTcv1+4sWLarly5fr8uXcr/9ISkpSUFCQ9YiIiLib0OHCypUqorVzB2nlzL7q+EwtdRv6ifYcYo0f8CCIjSqiLk2r6ZX3vs7rUGASzp7qjYiIsMk7kpKSssWwZMkSVa9eXc8++6zCwsL08MMPa8aMGU75vHl+V+/06dNVuXJlrV27Vp9//rlCQ0NtzmdN+WYpVaqUfvvtN+t727Ztq5CQEMXGxqpWrVpq2bKlatasedvrDRo0SL1797a+Tk5OJvnLZ7w8PVQm4safo6oVS2r7rmOaOn+1xr/eJo8jA/B3nqhcXKHBBfTf2V2sbR7ubhrZuZ5ebl5NsR2c88MQcJbjx4/bLFm7tdonSYcOHdKUKVPUu3dvvf766/r555/Vo0cPeXl5KTEx0aHx5HniFxYWpi5dumjx4sVq3rx5tvPr1q1TQECA9bWnp6f16zp16ujQoUPatGmTNmzYoO+//14TJkzQsGHDNHjw4Byvl1OJFflbpmHo2rXreR0GgFz49IddWrPjmE3bZyOe0YIfdmnuip15FBXytbu5EyO340oKDAzMdq/CrTIzM1W9enWNHj1akvTwww9r586dmjp1av5L/CTJw8NDHh45hxIZGXnbNX7SjUSwdu3aql27tgYMGKCRI0dq+PDhGjBggLy8vJwUMVzVsPe/VPyTlRVRtKAuX03VZ99s0fqt+/X5pG55HRqA//Hz8VRkeLD1dakiQapSJlQXL6fqxB+XdeFyqk3/6xmZ+v1Cig6cvHCfIwXuj2LFiqlSpUo2bRUrVtTnn3/u8Gu5ROLnSJUqVdL169eVmppK4mdCf164opeHztHvfyYr0N9HlaOK6/NJ3RT3WMW8Dg3A/1QtV1TLxv6f9fXol+IkSfNW7NQr477Jq7BgUq7wyLaaNWtq7969Nm379u1TqVKlHB2W6yd+Z8+eVWqq7b/+QkJC5OnpqXr16qlNmzaqXr26QkJCtGvXLr3++uuKi4v727Iq8qdJg9vmdQgA/saP/z2ugo3fyXV/1vUhv+vVq5eefPJJjR49Wq1atdJPP/2k6dOna/r06Q6/lssnftHR0dnaNm7cqMcff1wJCQmaPXu2Xn/9dV29elXh4eH617/+pTfffDMPIgUAAA8cJz2yzZ4i4qOPPqovvvhCgwYN0vDhwxUZGanx48erbVvHFzMshmEYDh/1AZKcnKygoCD9fu4SVULgAWFPtQhA3jOupypt1WBduuQ6P2uzfv5/v+OY/AMcH9OVy8mqX7WkS31m6QGo+AEAADiLk2/qdTl5uoEzAAAA7h8qfgAAwLxMVvIj8QMAAKblCtu53E9M9QIAAJgEFT8AAGBaFidt5+KULWIcgIofAACASVDxAwAApmWyezuo+AEAAJgFFT8AAGBeJiv5UfEDAAAwCSp+AADAtNjHDwAAAPkSFT8AAGBaZtvHj8QPAACYlsnu7WCqFwAAwCyo+AEAAPMyWcmPih8AAIBJUPEDAACmxXYuAAAAyJeo+AEAANMy23YuVPwAAABMgoofAAAwLZPd1EvFDwAAwCyo+AEAAPMyWcmPih8AAIBJUPEDAACmZbZ9/Ej8AACAabGdCwAAAPIlKn4AAMC0THZvBxU/AAAAs6DiBwAAzMtkJT8qfgAAACZBxQ8AAJiW2bZzoeIHAABgElT8AACAabGPHwAAAPIlKn4AAMC0THZTLxU/AAAAs6DiBwAAzMtkJT8SPwAAYFps5wIAAIB8iYofAAAwLydt5+KiBT8qfgAAAGZBxQ8AAJiWye7toOIHAABgFlT8AACAeZms5EfFDwAAwCSo+AEAANNiHz8AAADkS1T8AACAaVmctI+fU/YGdAAqfgAAACZBxQ8AAJiWyW7qJfEDAAAmZrLMj6leAAAAk6DiBwAATIvtXAAAAJAvUfEDAACmZZGTtnNx/JAOQcUPAADAJKj4AQAA0zLZTb1U/AAAAMyCih8AADAtHtkGAACAfImKHwAAMDFzrfKj4gcAAGASVPwAAIBpmW2NH4kfAAAwLXNN9DLVCwAAYBokfgAAwLSypnqdcdytMWPGyGKxqGfPng77nFlI/AAAAFzEzz//rGnTpumhhx5yyvgkfgAAwLQsTvwlScnJyTZHWlrabWO5cuWK2rZtqxkzZqhgwYJO+bwkfgAAAE4SERGhoKAg65GUlHTbvq+88oqeeuopxcfHOy0e7uoFAADm5eTbeo8fP67AwEBrs7e3d47d58+fr23btunnn392QjD/PxI/AAAAJwkMDLRJ/HJy/Phxvfbaa1qxYoV8fHycGg+JHwAAMC1X2Mdv69atOnv2rB555BFrW0ZGhtauXav3339faWlpcnd3d0hcJH4AAAB5qH79+vrvf/9r09ahQwdVqFBBAwYMcFjSJ5H4AQAAE3OFR7YFBASoSpUqNm1+fn4KCQnJ1n6vSPwAAIBp3bz1iqPHdUUkfgAAAC5m9erVThmXxA8AAJiXK9zdcR+xgTMAAIBJUPEDAACmZbKCHxU/AAAAs6DiBwAATMsVtnO5n6j4AQAAmAQVPwAAYGLO2cfPVVf5UfEDAAAwCSp+AADAtFjjBwAAgHyJxA8AAMAkmOoFAACmxVQvAAAA8iUqfgAAwLQsTtrOxTlbxNw7Kn4AAAAmQcUPAACYFmv8AAAAkC9R8QMAAKZlkXMeruaiBT8qfgAAAGZBxQ8AAJiXyUp+VPwAAABMgoofAAAwLfbxAwAAQL5ExQ8AAJiW2fbxI/EDAACmZbJ7O5jqBQAAMAsqfgAAwLxMVvKj4gcAAGASVPwAAIBpsZ0LAAAA8iUqfgAAwLTYzsVkDMOQJF1OTs7jSADklnE9Na9DAGCHrL+zWT9zXUmyk37+O2vce2X6xO/y5cuSpKjIiDyOBACA/O3y5csKCgrK6zAkSV5eXipatKjKOfHnf9GiReXl5eW08e+GxXDF9Ps+yszM1KlTpxQQECCLq9ZlcVeSk5MVERGh48ePKzAwMK/DAfA3+DubfxmGocuXLys8PFxubq5ze0FqaqquXbvmtPG9vLzk4+PjtPHvhukrfm5ubipRokRehwEnCgwM5IcI8ADh72z+5CqVvpv5+Pi4XGLmbK6TdgMAAMCpSPwAAABMgsQP+Za3t7eGDBkib2/vvA4FQC7wdxZwPtPf3AEAAGAWVPwAAABMgsQPAADAJEj8AAAATILEDwAAwCRI/PBAat++vSwWi8aMGWPTvnjxYpsnsGRkZGjcuHGKiYmRj4+PChYsqEaNGunHH3+83yEDpmMYhuLj45WQkJDt3OTJkxUcHKx///vfslgsOR5nzpyRJF29elWDBg1S2bJl5ePjo9DQUNWtW1dffvnl/f5IwAOPxA8PLB8fH40dO1YXLlzI8bxhGGrdurWGDx+u1157Tbt379bq1asVERGhevXqafHixfc3YMBkLBaLZs6cqc2bN2vatGnW9sOHD6t///6aNGmS9clJe/fu1enTp22OsLAwSVLXrl21aNEiTZo0SXv27NE333yjli1b6ty5c3nyuYAHGdu54IHUvn17nTt3TgcOHFCTJk301ltvSbpR8WvRooUMw9Cnn36q1q1ba8mSJWrSpInN+5955hmtWbNGR48elZ+fX158BMA0Zs+ere7du+vXX39V6dKlVb9+fQUHB2vRokVavXq14uLidOHCBQUHB+f4/uDgYE2YMEGJiYn3N3AgH6LihweWu7u7Ro8erUmTJunEiRPZzs+bN0/ly5fPlvRJUp8+fXTu3DmtWLHifoQKmFpiYqLq16+vjh076v3339fOnTttKoB/p2jRolq+fLkuX77sxCgBcyDxwwOtRYsWqlq1qoYMGZLt3L59+1SxYsUc35fVvm/fPqfGB+CG6dOna+fOnerZs6emT5+u0NBQm/MlSpSQv7+/9ahcubLNezds2KCQkBA9+uij6tWrF+t0gbtE4ocH3tixYzV79mzt3r072zlWMgCuISwsTF26dFHFihXVvHnzbOfXrVunHTt2WI/ly5dbz9WpU0eHDh3S999/r5YtW+q3335T7dq1NWLEiPv4CYD8gcQPD7w6deooISFBgwYNsmkvX758jsmgJGt7+fLlnR4fgBs8PDzk4eGR47nIyEhFRUVZj1KlStmc9/T0VO3atTVgwAB99913Gj58uEaMGKFr167dj9CBfIPED/nCmDFjtHTpUm3cuNHa1rp1a+3fv19Lly7N1v/dd99VSEiIGjRocD/DBOAglSpV0vXr15WamprXoQAPlJz/6QU8YGJiYtS2bVtNnDjR2ta6dWstXLhQiYmJevvtt1W/fn0lJyfrgw8+0JIlS7Rw4ULu6AVcxNmzZ7MlcSEhIfL09FS9evXUpk0bVa9eXSEhIdq1a5def/11xcXFKTAwMI8iBh5MVPyQbwwfPlyZmZnW1xaLRQsWLNDrr7+ucePGKTo6WrVr19bRo0e1evXqHNcZAcgb0dHRKlasmM2xdetWSVJCQoJmz56thg0bqmLFinr11VeVkJCgBQsW5HHUwIOHffwAAABMgoofAACASZD4AQAAmASJHwAAgEmQ+AEAAJgEiR8AAIBJkPgBAACYBIkfAACASZD4AQAAmASJHwCnaN++vc3TUerVq6eePXve9zhWr14ti8Wiixcv3raPxWLR4sWLcz3m0KFDVbVq1XuK68iRI7JYLNqxY8c9jQMA9iDxA0ykffv2slgsslgs8vLyUlRUlIYPH67r1687/dqLFi3SiBEjctU3N8kaAMB+HnkdAID765///KdmzpyptLQ0LV++XK+88oo8PT01aNCgbH2vXbsmLy8vh1y3UKFCDhkHAHD3qPgBJuPt7a2iRYuqVKlSevnllxUfH68lS5ZI+v+nZ0eNGqXw8HBFR0dLko4fP65WrVopODhYhQoVUrNmzXTkyBHrmBkZGerdu7eCg4MVEhKi/v3769bHgN861ZuWlqYBAwYoIiJC3t7eioqK0kcffaQjR44oLi5OklSwYEFZLBa1b99ekpSZmamkpCRFRkbK19dXsbGx+uyzz2yus3z5cpUvX16+vr6Ki4uziTO3BgwYoPLly6tAgQIqU6aMBg8erPT09Gz9pk2bpoiICBUoUECtWrXSpUuXbM5/+OGHqlixonx8fFShQgVNnjzZ7lgAwJFI/ACT8/X11bVr16yvv//+e+3du1crVqzQsmXLlJ6eroSEBAUEBGjdunX68ccf5e/vr3/+85/W97377ruaNWuWPv74Y61fv17nz5/XF198ccfrtmvXTv/5z380ceJE7d69W9OmTZO/v78iIiL0+eefS5L27t2r06dPa8KECZKkpKQkzZkzR1OnTtVvv/2mXr166fnnn9eaNWsk3UhQn376aTVp0kQ7duxQ586dNXDgQLu/JwEBAZo1a5Z27dqlCRMmaMaMGRo3bpxNnwMHDmjBggVaunSpvvnmG23fvl3dunWznp87d67efPNNjRo1Srt379bo0aM1ePBgzZ492+54AMBhDACmkZiYaDRr1swwDMPIzMw0VqxYYXh7ext9+/a1ni9SpIiRlpZmfc8nn3xiREdHG5mZmda2tLQ0w9fX1/j2228NwzCMYsWKGW+99Zb1fHp6ulGiRAnrtQzDMOrWrWu89tprhmEYxt69ew1JxooVK3KMc9WqVYYk48KFC9a21NRUo0CBAsaGDRts+nbq1Mlo06aNYRiGMWjQIKNSpUo25wcMGJBtrFtJMr744ovbnn/77beNatWqWV8PGTLEcHd3N06cOGFt+/rrrw03Nzfj9OnThmEYRtmyZY158+bZjDNixAjjiSeeMAzDMA4fPmxIMrZv337b6wKAo7HGDzCZZcuWyd/fX+np6crMzNRzzz2noUOHWs/HxMTYrOv75ZdfdODAAQUEBNiMk5qaqoMHD+rSpUs6ffq0HnvsMes5Dw8PVa9ePdt0b5YdO3bI3d1ddevWzXXcBw4c0NWrV9WgQQOb9mvXrunhhx+WJO3evdsmDkl64okncn2NLJ9++qkmTpyogwcP6sqVK7p+/boCAwNt+pQsWVLFixe3uU5mZqb27t2rgIAAHTx4UJ06ddKLL75o7XP9+nUFBQXZHQ8AOAqJH2AycXFxmjJliry8vBQeHi4PD9v/Dfj5+dm8vnLliqpVq6a5c+dmGys0NPSuYvD19bX7PVeuXJEkffXVVzYJl3Rj3aKjbNy4UW3bttWwYcOUkJCgoKAgzZ8/X++++67dsc6YMSNbIuru7u6wWAHAXiR+gMn4+fkpKioq1/0feeQRffrppwoLC8tW9cpSrFgxbd68WXXq1JF0o7K1detWPfLIIzn2j4mJUWZmptasWaP4+Phs57MqjhkZGda2SpUqydvbW8eOHbttpbBixYrWG1WybNq06e8/5E02bNigUqVK6Y033rC2HT16NFu/Y8eO6dSpUwoPD7dex83NTdHR0SpSpIjCw8N16NAhtW3b1q7rA4AzcXMHgDtq27atChcurGbNmmndunU6fPiwVq9erR49eujEiROSpNdee01jxozR4sWLtWfPHnXr1u2Oe/CVLl1aiYmJ6tixoxYvXmwdc8GCBZKkUqVKyWKxaNmyZfrjjz905coVBQQEqG/fvurVq5dmz56tgwcPatu2bZo0aZL1homuXbtq//796tevn/bu3at58+Zp1qxZdn3ecuXK6dixY5o/f74OHjyoiRMn5nijio+PjxITE/XLL79o3bp16tGjh1q1aqWiRYtKkoYNG6akpCRNnDhR+/bt03//+1/NnDlT7733nl3xAIAjkfgBuKMCBQpo7dq1KlmypJ5++mlVrFhRnTp1UmpqqrUC2KdPH73wwgtKTEzUE088oYCAALVo0eKO406ZMkUtW7ZUt27dVKFCBb344otKSUmRJBUvXlzDhg3TwIEDVaRIEXXv3l2SNGLECA0ePFhJSUmqWLGi/vnPf+qrr75SZGSkpBvr7j7//HMtXrxYsbGxmjp1qkaPHm3X523atKl69eql7t27q2rVqtqwYYMGDx6crV9UVJSefvppNW7cWA0bNtRDDz1ks11L586d9eGHH2rmzJmKiYlR3bp1NWvWLGusAJAXLMbtVl8DAAAgX6HiBwAAYBIkfgAAACZB4gcAAGASJH4AAAAmQeIHAABgEiR+AAAAJkHiBwAAYBIkfgAAACZB4gcAAGASJH4AAAAmQeIHAABgEiR+AAAAJkHiBwAAYBIkfgAAACZB4gcAAGASJH4AAAAmQeIHAABgEiR+gAvr2rWrLBaL9RgzZkxeh2QaycnJGjBggMqWLStvb28VKVJEzz//vA4ePJir9x85csTm9+52x63S09M1ceJE1ahRQ4GBgfLz81NUVJTatWunEydOWPutXbtWzz77rKKiohQYGChPT08VLVpUTz31lL755huHfR8A5C8WwzCMvA4CQHbp6ekqVqyYzp07Z22LjY3Vjh078i4ok0hOTlbt2rX166+/ZjtXsGBBrVmzRjExMXcc48iRI4qMjLxjHw8PD6Wnp1tfp6SkqHHjxlq7dm2O/detW6datWpJkkaOHKnBgwffduy5c+fqueeeu+P1AZiPR14HACBnK1assEn6JOmXX37Rnj17VKFChTyKyj4pKSny8/PL6zDsNnToUGvSV6dOHfXu3Vtff/21pk2bpgsXLqhTp0766aef7jhGsWLFtG7dumzt//nPfzR58mRJUvPmzW3O9e3b15r0Pfroo3rllVdUokQJnT17Vj/++KOCgoKsfYsXL67XXntNjz/+uMLCwnTq1CmNHj1au3fvliRNmjSJxA9AdgYAl/TCCy8YkgxJRuvWra1fDxkyJMf+x44dM1555RWjbNmyhre3txEcHGw8/vjjxvz582367dq1y0hMTDRKlixpeHl5GYULFzbi4uKMlStXGoZhGIcPH7Zeq27dujbvLVWqlPVcllWrVlnbEhMTjc8//9yIjY01vLy8rLEmJSUZdevWNYoXL274+PgYvr6+RsWKFY033njDSElJyfZZ7hRjcnKyUaBAAUOSUapUKSMzM9P6vuvXrxuFCxc2JBmFChUyrl27ZhiGYSQmJlpjXLVq1R2/72lpaUZwcLAhybBYLMapU6cMwzCMzMxMo0KFCtZxtmzZcsdxbicmJibHWE6dOmV4eHgYkozKlSsbqampdo/9xRdfWMeuXLnyXcUHIH8j8QNc0F9//WUEBAQYkozQ0FDjzJkz1qQgOjo6W//t27cbhQoVsv7Qv/lITEy09vvmm28MX1/fHPtlJWn3kvhFRkYaFosl25jR0dE5XlOSERcXZ3ON3MR4cyK3bt0663vXrl1rbX/ppZes7fYkflu3brX5PDfr0KGD9dy4cePuOE5Obo6vUqVKNuc++ugjm0S/cePGRsGCBY2goCCjadOmxm+//Xbbca9fv24cOnTIaN68uXWM7t272x0fgPyPqV7ABS1btkyXL1+WdGM6sEiRIqpXr55WrlypvXv3avv27Xr44YclSYZhqF27djp//rwkqUqVKhowYIAKFSqkzZs368qVK5Kkq1evql27dvrrr78kSbVr11b37t3l6+ur1atXO2RK9vDhw3r00UfVv39/eXp6yt/fX9KNm1QKFy6skJAQFShQQMnJyZo6daqWL1+uVatWacOGDXryySdzHWOnTp00e/ZsSTfWsmWte1uyZIk1ljZt2tzVZzhy5Ij16yJFiticCwsLs/ms9sqa4pWkV155xebcrl27rF/Pnz/f5tySJUu0evVqbdq0SRUrVrQ5V7RoUf3+++/W1x4eHmrTpo2SkpLsjg+ACeR15gkgu2eeecZaufn2228NwzCMqVOnWtv69+9v7bt9+3Zre2BgoHH27Nkcx7x5GjAyMvK2U4n3UvHz9/c3zp07l23MnTt3Gq1btzZKlChheHp6ZqvkTZgwwa4YDcMwypcvb0gyQkJCrFO6WZXF8PBwIyMj47bvvZM5c+ZYY6hTp47NucGDB1vPderUya5xz5w5Y/3sAQEBRnJyss35Tp062XxPevToYXz11VdGfHy8ta158+bZxi1SpIjN+7y9vY327dtnGx8ADMMw2M4FcDGXL1/WV199JUkqVKiQ/vGPf0iSnn76abm7u0uSPv30Uxn/uyF/37591vc+9thjCg0NzXHcm/vFx8fL29vb4bHXrFlThQoVsmk7evSonnzySc2fP18nTpywuYs1y8WLF+2OsWPHjpKkc+fO6ZtvvtH+/fu1d+9eSdL//d//yc3t7v73dnPlMy0tzebctWvXcuyXGzNmzLB+9nbt2ikgIMDm/M2ftUSJEho/frwaN26sDz74wNq+cuXKbOMuWbJEP/zwgz788ENVrlxZaWlpmjVrljp06GBXfADMgcQPcDGLFy9WamqqJOn8+fPy9PSUxWJRWFiYMjIyJN1IpjZu3OiU69+8t1zW9bL8+eefd3zvrVOjkjR79mwlJydLkp544gktXrxY69atU//+/a19MjMz7Y4zMTFRHh43Vqv8+9//1pdffmk9dy93s5YuXdr69c1TqJJ05swZ69d/t1XLzTIyMjR9+nTr627dumXrU7JkSevXERER1t+HUqVKWdtTUlKyfa9q1KihuLg4derUSUuXLrW2L1q0yPrnCACykPgBLuY///lPrvplrQMrX768te2nn366bXJ2c7+VK1faVK9udvOWITcnOuvXr1dKSsodY8ppQ+KTJ09av3799dfVrFkz1apVS5cuXbrrGKUba9saN24sSVq6dKn1+xYVFaXq1avfMc47qVKlivV7cPToUWv8hmFo06ZN1n61a9fO9ZhLly7V8ePHJUlxcXGqVKlStj41a9a0fn38+HFrRffYsWPW9vDwcGslM2sd5M1u/v4bhmFNuAEgCzd3AC7k3LlzWrFihSQpICBAo0ePtjl/7do19enTR5K0cOFCjR8/XrGxsapSpYp27typS5cuqX79+urfv78KFSqkrVu36sKFC3r33XfVsGFDhYWF6ezZszp8+LAaNmyo7t27y8fHR+vXr1dISIj69eun4OBghYSE6Ny5czpw4IC6du2q6OhovfPOO3f1mW6uWE2cOFFeXl7avHmzPvroo2x9cxtjlk6dOmnJkiX666+/tG3bNkk539TRvn17680gq1atUr169W4br5eXlzp27Khx48bJMAy1adNGffv21VdffWWdSq5evbqqVatmfU/p0qV19OhRSbImbDe7ebr21ps6stSsWVOVKlXSrl27dOLECfXu3VsNGzbU+PHjrX2eeeYZ69fFixfX888/rxo1aqhYsWI6fvy43n33Xev5iIiI2077AzCxvFxgCMDWzTdwPPPMMzn2qVq1qrVP1t57W7dute49d+tx83Yuy5cvN7y9ve+4VYphGMagQYOynS9WrJjNNbLcuo/frY4ePWrdd+/mo2bNmjleO7cxGoZhpKenG0WLFrXps2vXrmwx2LOdi2EYxqVLl4yHHnooxxiCg4ONX3/91aZ/Tje9ZNm7d691i5vixYsb6enpt73u5s2bDX9//xyvW6FCBeP8+fPWvjn1yTo8PT2NL7/88m8/JwDzYaoXcCE3T/M2bdo0xz5NmjSxfp013fvII4/ol19+0csvv6wyZcrIy8tLwcHBevzxx9WoUSNr/0aNGmnr1q164YUXVKJECXl6eiokJET16tWzmbp888039dJLLyk4OFh+fn5q1qxZtidH5FbJkiX13XffqUaNGvL19VXZsmU1efJkde7cOcf+uY1RurF1SWJiovV1bGxstu1O7kZgYKDWrVunfv36KTIyUl5eXgoLC9Nzzz2nn3/++W8f13azKVOmWKuAXbp0sa5LzEmNGjW0efNmPfvssypcuLA8PT0VGRmp3r17a+PGjSpYsKC175AhQ1S3bl0VK1ZMnp6e8vX1Vbly5dSpUydt2bLltn9+AJgbz+oF8EBbu3at6tatK0kaO3aszU0jAABbrPED8ED666+/lJycrClTpkiS3N3deTYtAPwNEj8AD6RGjRppzZo11tcdO3ZUiRIl8jAiAHB9JH4AHmiFCxfWM888o/feey+vQwEAl8caPwAAAJPgrl4AAACTIPEDAAAwCRI/AAAAkyDxAwAAMAkSPwAAAJMg8QMAADAJEj8AAACTIPEDAAAwif8PeWnRcvt0/YcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion matrix breakdown:\n",
            "  TN = 15 (true negatives)  | FP = 6 (false positives)\n",
            "  FN = 3 (false negatives) | TP = 14 (true positives)\n"
          ]
        }
      ],
      "source": [
        "# Plot confusion matrix for test set\n",
        "def plot_confusion_matrix(y_true, y_pred, labels=None, title=\"Confusion matrix\"):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix with robust label normalization.\n",
        "    \"\"\"\n",
        "\n",
        "    def norm(x):\n",
        "        return str(x).strip().upper()\n",
        "\n",
        "    y_true = [norm(y) for y in y_true]\n",
        "    y_pred = [norm(y) for y in y_pred]\n",
        "\n",
        "    if labels is None:\n",
        "        labels = [\"NO\", \"YES\"]\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "    plt.title(title)\n",
        "\n",
        "    accuracy = (cm[0][0] + cm[1][1]) / cm.sum()\n",
        "    plt.text(\n",
        "        0.5, -0.15, f'Accuracy: {accuracy:.3f}',\n",
        "        ha='center', transform=ax.transAxes,\n",
        "        fontsize=12, weight='bold'\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nConfusion matrix breakdown:\")\n",
        "    print(f\"  TN = {cm[0][0]} (true negatives)  | FP = {cm[0][1]} (false positives)\")\n",
        "    print(f\"  FN = {cm[1][0]} (false negatives) | TP = {cm[1][1]} (true positives)\")\n",
        "\n",
        "\n",
        "\n",
        "plot_confusion_matrix(\n",
        "    df_test[LABEL_COLUMN].tolist(),\n",
        "    df_test['prediction'].tolist(),\n",
        "    labels=[\"NO\", \"YES\"],\n",
        "    title=\"Test set confusion matrix\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcX48EKtkk2p",
        "outputId": "e14d1ce7-f32d-436e-856b-d07ef26744ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEV true counts : {'NO': 11, 'YES': 8}\n",
            "DEV pred counts : {'NO': 14, 'YES': 5}\n",
            "TEST true counts: {'NO': 21, 'YES': 17}\n",
            "TEST pred counts: {'YES': 20, 'NO': 18}\n",
            "\n",
            "Performance comparison: Development vs Test\n",
            "===========================================\n",
            "Metric     |     Dev |    Test\n",
            "--------------------------------\n",
            "Accuracy   |   0.737 |   0.763\n",
            "Precision  |   0.800 |   0.700\n",
            "Recall     |   0.500 |   0.824\n",
            "F1         |   0.615 |   0.757\n",
            "Kappa      |   0.431 |   0.529\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def norm_label(x):\n",
        "    s = str(x).strip().upper()\n",
        "    s = s.splitlines()[0].strip()\n",
        "    s = s.split()[0].strip() if s else s\n",
        "    s = s.strip(\" .,:;!()[]{}\\\"'\")\n",
        "    if s.startswith(\"Y\"): return \"YES\"\n",
        "    if s.startswith(\"N\"): return \"NO\"\n",
        "    return s\n",
        "\n",
        "# Use the correct prediction column in each split\n",
        "DEV_PRED_COL = \"pred_v1_norm\"   # df_dev has pred_v1_norm\n",
        "TEST_PRED_COL = \"prediction\"    # df_test has prediction\n",
        "\n",
        "# Normalize labels/preds for apples-to-apples evaluation\n",
        "dev_true = [norm_label(x) for x in df_dev[LABEL_COLUMN].tolist()]\n",
        "dev_pred = [norm_label(x) for x in df_dev[DEV_PRED_COL].tolist()]\n",
        "\n",
        "test_true = [norm_label(x) for x in df_test[LABEL_COLUMN].tolist()]\n",
        "test_pred = [norm_label(x) for x in df_test[TEST_PRED_COL].tolist()]\n",
        "\n",
        "print(\"DEV true counts :\", pd.Series(dev_true).value_counts(dropna=False).to_dict())\n",
        "print(\"DEV pred counts :\", pd.Series(dev_pred).value_counts(dropna=False).to_dict())\n",
        "print(\"TEST true counts:\", pd.Series(test_true).value_counts(dropna=False).to_dict())\n",
        "print(\"TEST pred counts:\", pd.Series(test_pred).value_counts(dropna=False).to_dict())\n",
        "\n",
        "dev_metrics = calculate_metrics(dev_true, dev_pred, positive_label=POSITIVE_LABEL)\n",
        "test_metrics = calculate_metrics(test_true, test_pred, positive_label=POSITIVE_LABEL)\n",
        "\n",
        "print(\"\\nPerformance comparison: Development vs Test\")\n",
        "print(\"===========================================\")\n",
        "print(f\"{'Metric':<10} | {'Dev':>7} | {'Test':>7}\")\n",
        "print(\"-\" * 32)\n",
        "\n",
        "for m in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"kappa\"]:\n",
        "    dv = dev_metrics[m]\n",
        "    tv = test_metrics[m]\n",
        "    # handle nan printing nicely\n",
        "    dv_str = f\"{dv:.3f}\" if pd.notna(dv) else \"nan\"\n",
        "    tv_str = f\"{tv:.3f}\" if pd.notna(tv) else \"nan\"\n",
        "    print(f\"{m.capitalize():<10} | {dv_str:>7} | {tv_str:>7}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "micbjbZqkk2p",
        "outputId": "8c7d91bf-7b79-4ab0-9918-596a91fa2283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DEVELOPMENT vs TEST COMPARISON\n",
            "================================================================================\n",
            "Metric        Development         Test   Difference\n",
            "--------------------------------------------------------------------------------\n",
            "Accuracy            0.737        0.763       +0.026\n",
            "Precision           0.800        0.700       -0.100\n",
            "Recall              0.500        0.824       +0.324\n",
            "F1                  0.615        0.757       +0.141\n",
            "Kappa               0.431        0.529       +0.098\n",
            "================================================================================\n",
            "\n",
            "Interpretation:\n",
            "  Test performance is higher than development performance.\n",
            "  This can occur if the test set contains clearer or less noisy examples.\n",
            "  There is no evidence of overfitting or data leakage.\n"
          ]
        }
      ],
      "source": [
        "# Side-by-side comparison\n",
        "if dev_metrics is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DEVELOPMENT vs TEST COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"{'Metric':<12} {'Development':>12} {'Test':>12} {'Difference':>12}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1', 'kappa']:\n",
        "        dev_val = dev_metrics[metric]\n",
        "        test_val = test_metrics[metric]\n",
        "        diff = test_val - dev_val\n",
        "        print(f\"{metric.capitalize():<12} {dev_val:>12.3f} {test_val:>12.3f} {diff:>+12.3f}\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Interpretation (updated to reflect correct methodology)\n",
        "    f1_diff = test_metrics['f1'] - dev_metrics['f1']\n",
        "\n",
        "    print(\"\\nInterpretation:\")\n",
        "    if abs(f1_diff) < 0.05:\n",
        "        print(\"  Performance is very similar between development and test sets.\")\n",
        "        print(\"  This suggests the classifier generalises well.\")\n",
        "    elif f1_diff > 0:\n",
        "        print(\"  Test performance is higher than development performance.\")\n",
        "        print(\"  This can occur if the test set contains clearer or less noisy examples.\")\n",
        "        print(\"  There is no evidence of overfitting or data leakage.\")\n",
        "    else:\n",
        "        print(\"  Test performance is lower than development performance.\")\n",
        "        if abs(f1_diff) < 0.10:\n",
        "            print(\"  The decrease is small and expected when moving to unseen data.\")\n",
        "        else:\n",
        "            print(\"  The decrease is notable and may indicate overfitting to the development set.\")\n",
        "else:\n",
        "    print(\"\\nNo development data available for comparison.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3HP6Jfxkk2p",
        "outputId": "d473b9b5-367b-49e3-b37e-3aebb2dd2272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total errors in test set: 38 out of 38 (100.0%)\n",
            "\n",
            "Breakdown:\n",
            "  False positives: 0\n",
            "  False negatives: 17\n"
          ]
        }
      ],
      "source": [
        "# Find errors in test set\n",
        "def find_errors(df, true_col, pred_col, positive_label, error_type=\"all\"):\n",
        "    \"\"\"\n",
        "    Find classification errors.\n",
        "    \"\"\"\n",
        "    if error_type == \"false_positive\":\n",
        "        return df[(df[true_col] != positive_label) & (df[pred_col] == positive_label)]\n",
        "    elif error_type == \"false_negative\":\n",
        "        return df[(df[true_col] == positive_label) & (df[pred_col] != positive_label)]\n",
        "    else:  # all errors\n",
        "        return df[df[true_col] != df[pred_col]]\n",
        "\n",
        "errors_test = find_errors(df_test, LABEL_COLUMN, 'prediction', POSITIVE_LABEL)\n",
        "fp_test = find_errors(df_test, LABEL_COLUMN, 'prediction', POSITIVE_LABEL, \"false_positive\")\n",
        "fn_test = find_errors(df_test, LABEL_COLUMN, 'prediction', POSITIVE_LABEL, \"false_negative\")\n",
        "\n",
        "print(f\"Total errors in test set: {len(errors_test)} out of {len(df_test)} ({len(errors_test)/len(df_test)*100:.1f}%)\")\n",
        "print(f\"\\nBreakdown:\")\n",
        "print(f\"  False positives: {len(fp_test)}\")\n",
        "print(f\"  False negatives: {len(fn_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Or803okkk2p",
        "outputId": "bb92b46b-94a4-44cd-cfc9-bc15792e6ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SAMPLE ERRORS FROM TEST SET\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "False negatives (predicted No, actually Yes):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "1. Description\n",
            "\n",
            "Offsite Medical Assistant I-Jackson Heights, NY, Full Time-Day\n",
            "\n",
            "The Medical Assistant I provides clinical office support to the supervising physician and performs patient care and administrative duties necessary to deliver quality patien...\n",
            "\n",
            "2. Description\n",
            "\n",
            "Offsite Medical Assistant I-Jackson Heights, NY, Full Time-Day\n",
            "\n",
            "The Medical Assistant I provides clinical office support to the supervising physician and performs patient care and administrative duties necessary to deliver quality patien...\n",
            "\n",
            "3. Responsibilities\n",
            "\n",
            " TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul a...\n"
          ]
        }
      ],
      "source": [
        "# Sample errors for review\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAMPLE ERRORS FROM TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if len(fp_test) > 0:\n",
        "    print(\"\\nFalse positives (predicted Yes, actually No):\")\n",
        "    print(\"-\"*80)\n",
        "    for i, (idx, row) in enumerate(fp_test.head(3).iterrows()):\n",
        "        print(f\"\\n{i+1}. {str(row[TEXT_COLUMN])[:250]}...\")\n",
        "\n",
        "if len(fn_test) > 0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"False negatives (predicted No, actually Yes):\")\n",
        "    print(\"-\"*80)\n",
        "    for i, (idx, row) in enumerate(fn_test.head(3).iterrows()):\n",
        "        print(f\"\\n{i+1}. {str(row[TEXT_COLUMN])[:250]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "ac14c620fd574cf080dc397da49151df",
            "0db830881a4c449b8dc38e412da2734e",
            "59ddb6a74e9f42b1b58ebe18f9a261a0",
            "cd446cb3450548c395ebe42b51c161fc",
            "95a50eafeef448009946427de5e852ad",
            "7b8443504e754eb6be47f0b1d4492c4b",
            "430c8974fb5046b8be51d06ea6aa5069",
            "cc55cb2d75e74a3aa2c1ec0b9d4f930a",
            "9b0902ccb1a2479f804ab4494303f278",
            "45ef8a8827d440c69cd468b199fa14dc",
            "d3fabea6b2bd46bdac7c3b9f1fb92f70"
          ]
        },
        "id": "qlnt13dmkk2q",
        "outputId": "a1df1517-5d49-440d-de7b-8db0ae1733a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying 3725 texts...\n",
            "Estimated time: ~9.3 minutes\n",
            "Estimated cost: ~$0.37\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Classifying texts:   0%|          | 0/3725 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac14c620fd574cf080dc397da49151df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classified dataset saved to: full_dataset_classified.csv\n",
            "\n",
            "Prediction distribution (normalized):\n",
            "prediction\n",
            "YES    2369\n",
            "NO     1356\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Proportion YES: 63.6%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "large_data_path = \"/notebooks/ai_jobs_strict_description_only.csv\"\n",
        "df_large = pd.read_csv(large_data_path)\n",
        "\n",
        "print(f\"Classifying {len(df_large)} texts...\")\n",
        "print(f\"Estimated time: ~{len(df_large) * 0.15 / 60:.1f} minutes\")\n",
        "print(f\"Estimated cost: ~${len(df_large) * 0.0001:.2f}\\n\")\n",
        "\n",
        "# Run classifier\n",
        "predictions_large = classify_batch(df_large[TEXT_COLUMN].tolist(), final_prompt)\n",
        "\n",
        "# ---- NEW: normalize predictions ----\n",
        "def normalize_pred(p):\n",
        "    if p is None:\n",
        "        return \"UNKNOWN\"\n",
        "    p = str(p).strip().upper()\n",
        "    # keep only the first token if the model outputs extra text\n",
        "    p = p.split()[0].strip(\".,:;()[]{}\")\n",
        "    if p in {\"YES\", \"NO\"}:\n",
        "        return p\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "df_large[\"prediction_raw\"] = predictions_large\n",
        "df_large[\"prediction\"] = df_large[\"prediction_raw\"].apply(normalize_pred)\n",
        "\n",
        "# Normalize POSITIVE_LABEL too\n",
        "POSITIVE_LABEL_NORM = str(POSITIVE_LABEL).strip().upper()\n",
        "\n",
        "# Save results\n",
        "out_path = \"full_dataset_classified.csv\"\n",
        "df_large.to_csv(out_path, index=False)\n",
        "print(f\"\\nClassified dataset saved to: {out_path}\")\n",
        "\n",
        "# Distribution of predictions\n",
        "print(\"\\nPrediction distribution (normalized):\")\n",
        "print(df_large[\"prediction\"].value_counts(dropna=False))\n",
        "\n",
        "print(f\"\\nProportion {POSITIVE_LABEL_NORM}: {(df_large['prediction'] == POSITIVE_LABEL_NORM).mean():.1%}\")\n",
        "\n",
        "# Optional: warn if the model isn't obeying the format\n",
        "unknown_rate = (df_large[\"prediction\"] == \"UNKNOWN\").mean()\n",
        "if unknown_rate > 0:\n",
        "    print(f\"\\nWarning: {unknown_rate:.1%} outputs were not strict YES/NO. Check prediction_raw.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv9mWkI5kk2q",
        "outputId": "6a6c2e50-3bfb-4371-df61-cc03165b3f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL VALIDITY ASSESSMENT\n",
            "================================================================================\n",
            "\n",
            "1. PREDICTIVE VALIDITY (Quantitative)\n",
            "--------------------------------------------------------------------------------\n",
            "   Test set F1 score: 0.757\n",
            "   Test set Kappa: 0.529\n",
            "   ✓ Good - acceptable for research use with caveats\n",
            "\n",
            "2. GENERALIZABILITY\n",
            "--------------------------------------------------------------------------------\n",
            "   Development F1: 0.615\n",
            "   Test F1: 0.757\n",
            "   Difference: +0.141\n",
            "   ⚠ Notable performance drop - may have overfit\n",
            "\n",
            "3. CONTENT VALIDITY (Qualitative)\n",
            "--------------------------------------------------------------------------------\n",
            "   Review the errors above and consider:\n",
            "   - Are error patterns systematic or random?\n",
            "   - Do errors reveal conceptual limitations?\n",
            "   - Are edge cases acceptable for your use case?\n",
            "\n",
            "4. SEMANTIC VALIDITY (Conceptual)\n",
            "--------------------------------------------------------------------------------\n",
            "   Ask yourself:\n",
            "   - Does the prompt capture the meaning of your construct?\n",
            "   - Would other researchers understand your definition?\n",
            "   - Did the LLM help you refine your conceptualisation?\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL VALIDITY ASSESSMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. PREDICTIVE VALIDITY (Quantitative)\")\n",
        "print(\"-\"*80)\n",
        "print(f\"   Test set F1 score: {test_metrics['f1']:.3f}\")\n",
        "print(f\"   Test set Kappa: {test_metrics['kappa']:.3f}\")\n",
        "\n",
        "if test_metrics['f1'] >= 0.85:\n",
        "    print(\"   ✓ Excellent - ready for large-scale use\")\n",
        "elif test_metrics['f1'] >= 0.70:\n",
        "    print(\"   ✓ Good - acceptable for research use with caveats\")\n",
        "elif test_metrics['f1'] >= 0.50:\n",
        "    print(\"   ⚠ Moderate - use with caution, consider hybrid approach\")\n",
        "else:\n",
        "    print(\"   ✗ Poor - reconsider approach or construct definition\")\n",
        "\n",
        "print(\"\\n2. GENERALIZABILITY\")\n",
        "print(\"-\"*80)\n",
        "if dev_metrics is not None:\n",
        "    f1_diff = test_metrics['f1'] - dev_metrics['f1']\n",
        "    print(f\"   Development F1: {dev_metrics['f1']:.3f}\")\n",
        "    print(f\"   Test F1: {test_metrics['f1']:.3f}\")\n",
        "    print(f\"   Difference: {f1_diff:+.3f}\")\n",
        "\n",
        "    if abs(f1_diff) < 0.05:\n",
        "        print(\"   ✓ Excellent generalisation\")\n",
        "    elif abs(f1_diff) < 0.10:\n",
        "        print(\"   ✓ Good generalisation\")\n",
        "    else:\n",
        "        print(\"   ⚠ Notable performance drop - may have overfit\")\n",
        "else:\n",
        "    print(\"   No development data for comparison\")\n",
        "\n",
        "print(\"\\n3. CONTENT VALIDITY (Qualitative)\")\n",
        "print(\"-\"*80)\n",
        "print(\"   Review the errors above and consider:\")\n",
        "print(\"   - Are error patterns systematic or random?\")\n",
        "print(\"   - Do errors reveal conceptual limitations?\")\n",
        "print(\"   - Are edge cases acceptable for your use case?\")\n",
        "\n",
        "print(\"\\n4. SEMANTIC VALIDITY (Conceptual)\")\n",
        "print(\"-\"*80)\n",
        "print(\"   Ask yourself:\")\n",
        "print(\"   - Does the prompt capture the meaning of your construct?\")\n",
        "print(\"   - Would other researchers understand your definition?\")\n",
        "print(\"   - Did the LLM help you refine your conceptualisation?\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RfpEo59kk2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7b04fd-93f4-441b-bdc7-4e7a71ae9cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# LLM-BASED TEXT CLASSIFICATION METHODOLOGY\n",
            "\n",
            "## Construct\n",
            "TODO: [Your construct name and definition]\n",
            "\n",
            "## Dataset\n",
            "- Total labeled data: 57 texts\n",
            "- Development set: 19 texts\n",
            "- Test set: 38 texts\n",
            "\n",
            "## Model\n",
            "- Model: gpt-4o-mini\n",
            "- Temperature: 0 (deterministic)\n",
            "- Prompt type: TODO: [MinZero/MaxZero/MaxFew]\n",
            "\n",
            "## Performance (Test Set)\n",
            "- Accuracy: 0.763\n",
            "- Precision: 0.700\n",
            "- Recall: 0.824\n",
            "- F1 score: 0.757\n",
            "- Cohen's Kappa: 0.529\n",
            "\n",
            "## Validity Assessment\n",
            "- Predictive validity: Good\n",
            "- Generalisability: TODO: [Describe dev vs test comparison]\n",
            "- Content validity: TODO: [Describe error analysis findings]\n",
            "- Semantic validity: TODO: [Describe prompt development process]\n",
            "\n",
            "## Limitations\n",
            "TODO: [Describe any limitations, edge cases, or caveats]\n",
            "\n",
            "## Prompt\n",
            "\n",
            "You are a research assistant analysing job descriptions to determine if the language used to describe AI-related responsibilities is vague or concrete.\n",
            "\n",
            "DEFINITION:\n",
            "Answer \"Yes\" (vague AI skill framing) if the job description mentions AI/ML (or related terms) but does NOT specify at least ONE concrete implementation detail such as:\n",
            "- Tasks (build/train/fine-tune/deploy/evaluate/monitor, create prompts/pipelines)\n",
            "- Tools/tech (LLMs, GPT, TensorFlow, PyTorch, scikit-learn, Azure/AWS/GCP, Databricks, vector DB, RAG)\n",
            "- Data/inputs (customer data, documents, logs, images, etc.)\n",
            "- Outputs/deliverables (models, dashboards, copilots, classifiers, forecasts, recommender systems)\n",
            "- Operational details (A/B tests, metrics, drift, MLOps, CI/CD, governance)\n",
            "\n",
            "Answer \"No\" if AI is mentioned AND the posting includes at least ONE clear concrete implementation detail above that is explicitly tied to AI-related work in the role.\n",
            "\n",
            "IMPORTANT RULES:\n",
            "- Consider the entire posting text (including company/mission sections).\n",
            "- If AI is mentioned in the posting, first look for specific tasks, tools, data, outputs, or operational details connected to AI.\n",
            "- If AI is mentioned anywhere in the posting and you do NOT find any specific tasks/tools/data/outputs/operational details tied to AI, answer \"Yes\".\n",
            "- Do NOT treat generic phrases as concrete, such as: \"AI-powered\", \"AI-enabled\", \"leveraging AI\", \"using AI tools\", \"data-driven\", \"intelligent automation\", \"advanced analytics\", \"informed decision-making\", \"innovation\", \"autonomy\", \"computer vision\", \"sensor fusion\" unless the text ALSO specifies named tasks, tools, data, or outputs.\n",
            "- If AI is not mentioned anywhere, answer \"No\".\n",
            "- In borderline or uncertain cases where AI is mentioned but it is unclear whether the description is concrete, answer \"Yes\" (vague AI skill framing).\n",
            "- If AI or related terms are mentioned only in the description of the company, business unit, or its “next‑generation capabilities” (for example, “we harness the power of data and digital to drive capabilities in artificial intelligence, robotics, automation, and analytics”), and there are no AI‑related tasks or tools in the listed responsibilities for this role, answer \"Yes\" (vague AI skill framing).\n",
            "\n",
            "SPECIAL CASE:\n",
            "- If AI or artificial intelligence is mentioned only in the description of the overall organisation or its technology strategy (and not in the specific responsibilities of this role), and there are no concrete AI tasks/tools/data/outputs for the role, answer \"Yes\" (vague AI skill framing).\n",
            "\n",
            "BORDERLINE CASES:\n",
            "- If AI is mentioned only in a generic company/mission statement and not in the role responsibilities, and there are no concrete AI tasks/tools/data/outputs, answer \"Yes\".\n",
            "- If the role describes concrete tasks that clearly depend on an AI or ML system (for example, \"use our ML model output to prioritise leads\") but does not name the model, answer \"No\" because the AI use is operationally specific.\n",
            "- If the posting lists \"AI tools\" or \"AI platforms\" in a skills list but does not describe any specific AI-related tasks, tools, data, or outputs, answer \"Yes\".\n",
            "- If the role sits in a business area that uses AI (e.g. “digital solutions”, “AI, robotics, automation, analytics”) but the responsibilities are standard functional work (such as payroll, HR operations, finance operations) with no explicit AI tasks or tools, answer \"Yes\".\n",
            "\n",
            "FEW-SHOT EXAMPLES:\n",
            "\n",
            "Text: \"Takeda Business Solutions (TBS) … harnesses the power of data and digital to optimize end-to-end processes across Finance, Procurement and HR. TBS is a driver of the latest technology and next generation capabilities in artificial intelligence, robotics, automation, and analytics…\" (This specific Payroll Operations Manager role has no AI-related tasks or tools listed in its responsibilities.)\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"The Mount Sinai Health System … offers comprehensive health care solutions … leveraging innovative approaches such as artificial intelligence and informatics while keeping patients’ medical and emotional needs at the center of all treatment.\" (The specific Medical Assistant role listed in this posting has no AI-related tasks or tools.)\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Drive AI innovation across the organization to enhance decision-making.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Build and deploy machine learning models using Python and TensorFlow to predict customer churn.\"\n",
            "Answer: No\n",
            "\n",
            "Text: \"Leverage AI tools to improve operational efficiency.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Develop LLM-powered document classification pipelines using GPT-4 and a vector database for retrieval-augmented generation.\"\n",
            "Answer: No\n",
            "\n",
            "Text: \"We leverage artificial intelligence and informatics to revolutionize healthcare.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"We leverage artificial intelligence and informatics to transform healthcare delivery.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"Our organization uses AI-powered systems to improve operational effectiveness.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"We harness the power of data and digital to optimize end-to-end processes and drive next generation capabilities in artificial intelligence, robotics, automation, and analytics.\"\n",
            "Answer: Yes\n",
            "\n",
            "Text: \"This role uses an AI-based scheduling system developed by a central IT team; no AI development or configuration is required.\"\n",
            "Answer: No\n",
            "\n",
            "TASK:\n",
            "Read the text below and determine if it contains vague AI skill framing.\n",
            "\n",
            "Before answering, check:\n",
            "1) Does the posting mention AI/ML anywhere?\n",
            "2) Does it include a specific task/tool/data/output/operational detail tied to AI?\n",
            "- If (1) yes and (2) no → Yes\n",
            "- If (1) yes and (2) yes → No\n",
            "- If (1) no → No\n",
            "\n",
            "Question: Does this posting contain vague AI skill framing according to the definition above?\n",
            "Respond with ONLY \"Yes\" or \"No\".\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Documentation saved to: classification_methodology.md\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate documentation summary\n",
        "doc = f\"\"\"\n",
        "# LLM-BASED TEXT CLASSIFICATION METHODOLOGY\n",
        "\n",
        "## Construct\n",
        "TODO: [Your construct name and definition]\n",
        "\n",
        "## Dataset\n",
        "- Total labeled data: {len(df_dev) + len(df_test) if df_dev is not None else len(df_test)} texts\n",
        "- Development set: {len(df_dev) if df_dev is not None else 'N/A'} texts\n",
        "- Test set: {len(df_test)} texts\n",
        "\n",
        "## Model\n",
        "- Model: gpt-4o-mini\n",
        "- Temperature: 0 (deterministic)\n",
        "- Prompt type: TODO: [MinZero/MaxZero/MaxFew]\n",
        "\n",
        "## Performance (Test Set)\n",
        "- Accuracy: {test_metrics['accuracy']:.3f}\n",
        "- Precision: {test_metrics['precision']:.3f}\n",
        "- Recall: {test_metrics['recall']:.3f}\n",
        "- F1 score: {test_metrics['f1']:.3f}\n",
        "- Cohen's Kappa: {test_metrics['kappa']:.3f}\n",
        "\n",
        "## Validity Assessment\n",
        "- Predictive validity: {'Excellent' if test_metrics['f1'] >= 0.85 else 'Good' if test_metrics['f1'] >= 0.70 else 'Moderate'}\n",
        "- Generalisability: TODO: [Describe dev vs test comparison]\n",
        "- Content validity: TODO: [Describe error analysis findings]\n",
        "- Semantic validity: TODO: [Describe prompt development process]\n",
        "\n",
        "## Limitations\n",
        "TODO: [Describe any limitations, edge cases, or caveats]\n",
        "\n",
        "## Prompt\n",
        "{final_prompt}\n",
        "\"\"\"\n",
        "\n",
        "print(doc)\n",
        "\n",
        "# Save to file\n",
        "with open('classification_methodology.md', 'w') as f:\n",
        "    f.write(doc)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Documentation saved to: classification_methodology.md\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9J4C8Oskk2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986a8828-e8a3-40c7-8efd-b8dbe40e19d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results saved to: test_results_final.csv\n",
            "Metrics summary saved to: metrics_summary.csv\n",
            "\n",
            "All results saved!\n"
          ]
        }
      ],
      "source": [
        "# Save test results\n",
        "df_test.to_csv('test_results_final.csv', index=False)\n",
        "print(\"Test results saved to: test_results_final.csv\")\n",
        "\n",
        "# Save metrics summary\n",
        "metrics_df = pd.DataFrame([test_metrics]).T\n",
        "metrics_df.columns = ['Test Set']\n",
        "if dev_metrics is not None:\n",
        "    metrics_df['Development Set'] = pd.Series(dev_metrics)\n",
        "    metrics_df['Difference'] = metrics_df['Test Set'] - metrics_df['Development Set']\n",
        "\n",
        "metrics_df.to_csv('metrics_summary.csv')\n",
        "print(\"Metrics summary saved to: metrics_summary.csv\")\n",
        "\n",
        "print(\"\\nAll results saved!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}